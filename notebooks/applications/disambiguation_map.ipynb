{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Peripleo Web Map from Disambiguated Data\n",
        "\n",
        "This notebook demonstrates how to transform disambiguated data into a **publicly accessible Peripleo web map**.  \n",
        "It illustrates the potential of data produced by disambiguation processes and provides a step-by-step pipeline for generating an interactive map interface.\n",
        "\n",
        "> **Tip:** To avoid conflicts, make a copy of this Colab notebook at the outset and work within that:  \n",
        "> **File > Save a Copy**\n",
        "\n",
        "---\n",
        "\n",
        "## Input\n",
        "The notebook expects a **spreadsheet of disambiguated data**.\n",
        "\n",
        "Each row should include:\n",
        "\n",
        "- Place information  \n",
        "- Metadata for:\n",
        "  - `Object ID`  \n",
        "  - `Object Title`  \n",
        "  - Associated `Wikidata ID`\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "The notebook produces a **URL to a publicly available [Peripleo](https://github.com/britishlibrary/peripleo) web map**, displaying the disambiguated places and associated objects.\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Overview\n",
        "The notebook performs the following steps:\n",
        "\n",
        "1. **Query Wikidata** to obtain coordinate data for each object (row).  \n",
        "2. **Generate GeoJSON** in the Linked Places format required by Peripleo.  \n",
        "3. **Publish the data** to GitHub Pages within a cloned Peripleo repository.\n",
        "\n",
        "The resulting web map allows you to explore the disambiguated dataset in an interactive, geographic context.\n"
      ],
      "metadata": {
        "id": "h1RjXVL8n8BU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create GitHub Secret for Colab\n",
        "\n",
        "This step allows the notebook to access your GitHub account via the **GitHub API**. The publication step below will not work without it.\n",
        "\n",
        "\n",
        "‚ö†Ô∏è **Warning:** Keep your token private and do **not** share it outside this notebook.\n",
        "\n",
        "---\n",
        "\n",
        "### Prerequisites\n",
        "- You must have a [GitHub account](https://docs.github.com/en/get-started/start-your-journey/creating-an-account-on-github).\n",
        "\n",
        "---\n",
        "\n",
        "### Steps to Generate a Personal Access Token (Classic)\n",
        "\n",
        "1. Go to [GitHub Personal Access Tokens](https://github.com/settings/tokens)  \n",
        "2. On the left, select **Tokens (classic)**  \n",
        "3. Click **Generate new token (classic)**  \n",
        "4. Add a descriptive **Note** for your reference  \n",
        "5. Under **Select scopes**, tick the **repo** checkbox  \n",
        "6. Scroll down and click **Generate token**  \n",
        "7. Copy the **token value** displayed ‚Äî this is your secret\n",
        "\n",
        "---\n",
        "\n",
        "### Steps to Add the Token in Colab\n",
        "\n",
        "1. In Colab, click the **key icon** on the left sidebar  \n",
        "2. Click **Add new secret**  \n",
        "3. Set:\n",
        "   - **Name:** `GITHUB_TOKEN`  \n",
        "   - **Value:** paste the token you copied  \n",
        "4. Toggle **Use Notebook Access** to allow this notebook to access the secret\n"
      ],
      "metadata": {
        "id": "bD4CjP6OSZ5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Install Dependencies\n",
        "\n",
        "!pip install folium SPARQLWrapper geojson PyGithub geopandas fiona\n"
      ],
      "metadata": {
        "id": "IIkZqp2YBXqA",
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71327ba4-dd33-4ab5-ef8d-5149e6952796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.12/dist-packages (0.20.0)\n",
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting geojson\n",
            "  Downloading geojson-3.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting PyGithub\n",
            "  Downloading pygithub-2.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from folium) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from folium) (2.32.4)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium) (2025.4.0)\n",
            "Collecting rdflib>=6.1.1 (from SPARQLWrapper)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (2.5.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from fiona) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from fiona) (2025.8.3)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.12/dist-packages (from fiona) (8.2.1)\n",
            "Collecting click-plugins>=1.0 (from fiona)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting cligj>=0.5 (from fiona)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading geojson-3.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading pygithub-2.8.1-py3-none-any.whl (432 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m432.7/432.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdflib, geojson, cligj, click-plugins, SPARQLWrapper, pynacl, fiona, PyGithub\n",
            "Successfully installed PyGithub-2.8.1 SPARQLWrapper-2.0.0 click-plugins-1.1.1.2 cligj-0.7.2 fiona-1.10.1 geojson-3.2.0 pynacl-1.6.0 rdflib-7.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Query Wikidata to Retrieve Coordinates\n",
        "\n",
        "#@markdown Your spreadsheet should include (at least) the following columns:\n",
        "#@markdown - `entity_label` ‚Äì the name of the place or object\n",
        "#@markdown - `entity_text` ‚Äì additional descriptive text\n",
        "#@markdown - `wikidata_uri` ‚Äì the corresponding Wikidata ID\n",
        "\n",
        "#@markdown Enter the **URL or file path** to your spreadsheet in the box below:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import time # Import the time module\n",
        "\n",
        "URL = \"http://145.38.185.232/enriching/disambiguation_annotation.csv\" #@param {type:'string'}\n",
        "\n",
        "#@title Function to fetch from Wikidata\n",
        "\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "def query_wikidata(uri, endpoint=\"https://query.wikidata.org/sparql\", cache=dict()):\n",
        "\n",
        "    if uri in cache:\n",
        "        return cache[uri]\n",
        "\n",
        "    q = \"\"\"\n",
        "    SELECT DISTINCT ?uri ?uriLabel ?uriDescription ?latitude ?longitude WHERE {\n",
        "        ?uri wdt:P31|wdt:P279 [] .\n",
        "\n",
        "        OPTIONAL {\n",
        "            ?uri p:P625 ?coordinate.\n",
        "            ?coordinate ps:P625 ?coord.\n",
        "            ?coordinate psv:P625 ?coordinate_node.\n",
        "            ?coordinate_node wikibase:geoLongitude ?longitude.\n",
        "            ?coordinate_node wikibase:geoLatitude ?latitude.\n",
        "            }\n",
        "\n",
        "        VALUES ?uri { <URIHIER> }\n",
        "\n",
        "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en,nl,de,fr,it,es,\". }\n",
        "    }\n",
        "    \"\"\".replace(\n",
        "        \"URIHIER\", uri\n",
        "    )\n",
        "\n",
        "    sparql = SPARQLWrapper(endpoint)\n",
        "    sparql.setQuery(q)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "\n",
        "    if len(results[\"results\"][\"bindings\"]) == 0:\n",
        "        return \"\", \"\", \"\", \"\"\n",
        "\n",
        "    label = results[\"results\"][\"bindings\"][0][\"uriLabel\"][\"value\"]\n",
        "    description = (\n",
        "        results[\"results\"][\"bindings\"][0].get(\"uriDescription\", {}).get(\"value\")\n",
        "    )\n",
        "    latitude = results[\"results\"][\"bindings\"][0].get(\"latitude\", {}).get(\"value\")\n",
        "    longitude = results[\"results\"][\"bindings\"][0].get(\"longitude\", {}).get(\"value\")\n",
        "\n",
        "    cache[uri] = label, description, latitude, longitude\n",
        "    return label, description, latitude, longitude\n",
        "\n",
        "#Test Wikidata Query\n",
        "# cache = dict()\n",
        "# uri = \"http://www.wikidata.org/entity/Q43631\"\n",
        "\n",
        "# label, description, latitude, longitude = query_wikidata(uri, cache=cache)\n",
        "\n",
        "# print(f\"Label: {label}\")\n",
        "# print(f\"Description: {description}\")\n",
        "# print(f\"Latitude: {latitude}\")\n",
        "# print(f\"Longitude: {longitude}\")\n",
        "\n",
        "\n",
        "def enrich_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "  cache = dict()\n",
        "\n",
        "  for i, row in df.iterrows():\n",
        "\n",
        "    if row.entity_label != \"LOC\":\n",
        "      continue\n",
        "    elif pd.isna(row.wikidata_uri):\n",
        "      continue\n",
        "\n",
        "    if '/wiki/' in row.wikidata_uri:\n",
        "      uri = row.wikidata_uri.replace('https://www.wikidata.org/wiki/', 'http://www.wikidata.org/entity/')\n",
        "      df.loc[i, \"wikidata_uri\"] = uri\n",
        "    else:\n",
        "      uri = row.wikidata_uri\n",
        "\n",
        "    label, description, latitude, longitude = query_wikidata(uri, cache=cache)\n",
        "\n",
        "    df.loc[i, \"wikidata_label\"] = label\n",
        "    df.loc[i, \"wikidata_description\"] = description\n",
        "    df.loc[i, \"wikidata_latitude\"] = latitude\n",
        "    df.loc[i, \"wikidata_longitude\"] = longitude\n",
        "\n",
        "    time.sleep(0.5) # Add a small delay between queries\n",
        "\n",
        "  return df\n",
        "\n",
        "df = pd.read_csv(URL)\n",
        "df.head()\n",
        "\n",
        "df = enrich_df(df)\n",
        "df[df['entity_label'] == 'LOC'].head()"
      ],
      "metadata": {
        "id": "GNCeLej5FceK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Generate GeoJSON in the Linked Places Format (LPF)\n",
        "\n",
        "#@markdown This step converts your spreadsheet data into **GeoJSON** following the **[Linked Places Format (LPF)](https://github.com/LinkedPasts/linked-places-format)**, which is the standard format used by the Peripleo web map for visualising place-based data.\n",
        "\n",
        "\n",
        "from geojson import Feature, Point\n",
        "import json\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point as ShapelyPoint\n",
        "\n",
        "def get_robust_bounds(geometries):\n",
        "    \"\"\"\n",
        "    Computes a bounding box for a set of Shapely geometries,\n",
        "    handling cases where geometries cross the antimeridian.\n",
        "\n",
        "    Returns a bbox in the format [min_lon, min_lat, max_lon, max_lat].\n",
        "    \"\"\"\n",
        "    if not geometries:\n",
        "        return None\n",
        "\n",
        "    # Get the simple min/max bounds first\n",
        "    all_lon = [g.bounds[0] for g in geometries] + [g.bounds[2] for g in geometries]\n",
        "    all_lat = [g.bounds[1] for g in geometries] + [g.bounds[3] for g in geometries]\n",
        "\n",
        "    min_lon = min(all_lon)\n",
        "    min_lat = min(all_lat)\n",
        "    max_lon = max(all_lon)\n",
        "    max_lat = max(all_lat)\n",
        "\n",
        "    # Check for antimeridian crossing\n",
        "    # If the span is > 180, the points must cross the antimeridian\n",
        "    if (max_lon - min_lon) > 180:\n",
        "        min_lon = -180\n",
        "        max_lon = 180\n",
        "\n",
        "    return [min_lon, min_lat, max_lon, max_lat]\n",
        "\n",
        "def df2lp(df: pd.DataFrame) -> dict:\n",
        "\n",
        "  features = []\n",
        "  geometries = []\n",
        "\n",
        "  # Ensure the DataFrame is sorted for correct grouping logic\n",
        "  df_sorted = df.sort_values(by='wikidata_uri')\n",
        "\n",
        "  for _, row in df_sorted.iterrows():\n",
        "    if row.entity_label != \"LOC\" or pd.isna(row.wikidata_uri):\n",
        "        continue\n",
        "    if not row.wikidata_latitude or not row.wikidata_longitude:\n",
        "        continue\n",
        "\n",
        "    # Construct the GeoJSON Feature\n",
        "    longitude = float(row.wikidata_longitude)\n",
        "    latitude = float(row.wikidata_latitude)\n",
        "\n",
        "    point = Point([longitude, latitude])\n",
        "\n",
        "    uri = f'https://knowledgebase.sloanelab.org/resource/?uri=http%3A%2F%2Fsloanelab.org%2FE73%2Fbm_dataset%2F{row[\"Unique ID\"]}'\n",
        "\n",
        "    feature = Feature(\n",
        "      geometry=point,\n",
        "      properties={\n",
        "        \"title\": row['Unique ID'],\n",
        "        \"description\": \"Description of the object\",\n",
        "        \"url\": f\"https://www.britishmuseum.org/collection/object/{row['Unique ID']}\"\n",
        "      },\n",
        "      # Simplified links for clarity\n",
        "      links=[{\n",
        "        \"type\": \"seeAlso\",\n",
        "        \"label\": row['Unique ID'],\n",
        "        \"url\": uri\n",
        "      }]\n",
        "    )\n",
        "    feature[\"@id\"] = uri\n",
        "    features.append(feature)\n",
        "\n",
        "    # Collect Shapely geometries for bounding box calculation\n",
        "    geometries.append(ShapelyPoint(longitude, latitude))\n",
        "\n",
        "\n",
        "  # Compute the bounding box\n",
        "  bbox = get_robust_bounds(geometries)\n",
        "\n",
        "  data = {\n",
        "     \"type\": \"FeatureCollection\",\n",
        "     \"@context\": \"https://raw.githubusercontent.com/LinkedPasts/linked-places/master/linkedplaces-context-v1.1.jsonld\",\n",
        "     \"features\": features,\n",
        "     \"bbox\": bbox\n",
        "  }\n",
        "\n",
        "  return data\n",
        "\n",
        "# print(json.dumps(df2lp(df), indent=2))\n"
      ],
      "metadata": {
        "id": "chmXlitRGtvi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Preliminary Visualisation of Linked Places Format Data\n",
        "\n",
        "#@markdown This cell provides a **lightweight, interactive map** to preview your data in the **Linked Places Format (LPF)**, without the need to fully build the Peripleo web application.\n",
        "\n",
        "#@markdown **What it does:**\n",
        "#@markdown - Converts your DataFrame into a **GeoJSON object** using the `df2lp()` function.\n",
        "#@markdown - Determines a bounding box (if available) to **fit the map to your data**.\n",
        "#@markdown - Adds **interactive markers** for each place, including:\n",
        "#@markdown   - Title\n",
        "#@markdown   - Description (if available)\n",
        "#@markdown   - Link to the associated website or resource\n",
        "#@markdown - Uses **Folium**, a Python mapping library, to render an **interactive map** directly in the notebook.\n",
        "\n",
        "#@markdown This is ideal for quickly inspecting your dataset visually before publishing it in Peripleo.\n",
        "\n",
        "\n",
        "# Import the necessary libraries\n",
        "import folium\n",
        "import json\n",
        "\n",
        "# Assuming df2lp(df) is defined and returns a GeoJSON object\n",
        "# with a bbox property.\n",
        "geojson_data = df2lp(df)\n",
        "\n",
        "# Check if a bbox exists in the GeoJSON data\n",
        "if 'bbox' in geojson_data and geojson_data['bbox']:\n",
        "    bbox = geojson_data['bbox']\n",
        "    # Folium's fit_bounds() expects a list of [[min_lat, min_lon], [max_lat, max_lon]]\n",
        "    folium_bounds = [[bbox[1], bbox[0]], [bbox[3], bbox[2]]]\n",
        "    # 1. Initialize the map with the bounding box\n",
        "    folium_map = folium.Map()\n",
        "    folium_map.fit_bounds(folium_bounds)\n",
        "else:\n",
        "    # Fallback to a default location if no bbox is available\n",
        "    folium_map = folium.Map(location=[51.509, -0.12], zoom_start=12)\n",
        "\n",
        "# 2. Loop through each GeoJSON feature to add a marker\n",
        "for feature in geojson_data['features']:\n",
        "    # Extract properties and coordinates\n",
        "    properties = feature['properties']\n",
        "    coordinates = feature['geometry']['coordinates']\n",
        "\n",
        "    # GeoJSON coordinates are [longitude, latitude]\n",
        "    lat = coordinates[1]\n",
        "    lon = coordinates[0]\n",
        "\n",
        "    # Use an f-string to embed the title and URL into HTML\n",
        "    popup_html = f\"\"\"\n",
        "    <h3>{properties['title']}</h3>\n",
        "    <p>{properties.get('description', 'No description available.')}</p>\n",
        "    <a href=\"{properties['url']}\" target=\"_blank\">Visit website</a>\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the Folium popup object with the HTML\n",
        "    popup = folium.Popup(popup_html, max_width=300)\n",
        "\n",
        "    # Add a marker to the map\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        popup=popup,\n",
        "        tooltip=properties['title'],\n",
        "        icon=folium.Icon(color='blue', icon='info-sign')\n",
        "    ).add_to(folium_map)\n",
        "\n",
        "# 3. Display the map\n",
        "folium_map"
      ],
      "metadata": {
        "id": "pO6CLhLgf-AB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Make Peripleo app available on Github Pages\n",
        "\n",
        "\n",
        "#@markdown Please enter your GitHub username and a name for the new repository:\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "from github import Github, GithubException, Auth\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- 1. SET YOUR GITHUB REPOSITORY ---\n",
        "GITHUB_USERNAME = \"your-github-username-here\" #@param {type:\"string\"}\n",
        "REPO_NAME = \"test-peripleo-app\" #@param {type:\"string\"}\n",
        "SOURCE_REPO_OWNER = \"britishlibrary\"\n",
        "SOURCE_REPO_NAME = \"peripleo\"\n",
        "\n",
        "GEOJSON_FILE_PATH = \"docs/data/historical_data.geojson\"\n",
        "CONFIG_FILE_PATH = \"docs/peripleo.config.json\"\n",
        "\n",
        "# --- 2. ACCESS YOUR GITHUB TOKEN FROM COLAB SECRETS ---\n",
        "try:\n",
        "    github_token = userdata.get('GITHUB_TOKEN')\n",
        "except KeyError:\n",
        "    raise ValueError(\"GITHUB_TOKEN not found. Please set it as a Colab secret.\")\n",
        "\n",
        "# --- 3. PREPARE THE API REQUESTS ---\n",
        "# Headers for the template import API call (requires special media type)\n",
        "template_headers = {\n",
        "    \"Authorization\": f\"token {github_token}\",\n",
        "    \"Accept\": \"application/vnd.github.baptiste-preview+json\"\n",
        "}\n",
        "\n",
        "# Standard headers for all other authenticated API calls\n",
        "standard_headers = {\n",
        "    \"Authorization\": f\"token {github_token}\",\n",
        "    \"Accept\": \"application/vnd.github.v3+json\"\n",
        "}\n",
        "\n",
        "repo_data = {\n",
        "    \"owner\": GITHUB_USERNAME,\n",
        "    \"name\": REPO_NAME,\n",
        "    \"description\": \"Peripleo map generated from Colab\",\n",
        "    \"private\": False\n",
        "}\n",
        "template_url = f\"https://api.github.com/repos/{SOURCE_REPO_OWNER}/{SOURCE_REPO_NAME}/generate\"\n",
        "\n",
        "# --- 4. AUTHENTICATE WITH PYGITHUB ---\n",
        "auth = Auth.Token(github_token)\n",
        "g = Github(auth=auth)\n",
        "user = g.get_user()\n",
        "print(f\"Authenticated as: {user.login}\")\n",
        "\n",
        "# --- 5. AUTOMATED WORKFLOW ---\n",
        "print(f\"--- Step 1: Importing '{SOURCE_REPO_NAME}' as a new private repository named '{REPO_NAME}' ---\")\n",
        "try:\n",
        "    new_repo = user.get_repo(REPO_NAME)\n",
        "    print(f\"Repository '{REPO_NAME}' already exists under your account. Skipping import.\")\n",
        "except GithubException as e:\n",
        "    if e.status == 404:\n",
        "        print(f\"Repository '{REPO_NAME}' not found. Importing from template now...\")\n",
        "        response = requests.post(template_url, headers=template_headers, json=repo_data)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        repo_found = False\n",
        "        while not repo_found:\n",
        "            try:\n",
        "                new_repo = user.get_repo(REPO_NAME)\n",
        "                repo_found = True\n",
        "            except GithubException:\n",
        "                print(\"Waiting for repository creation...\", end=\"\\r\")\n",
        "                time.sleep(5)\n",
        "\n",
        "        print(f\"\\nNew repository '{REPO_NAME}' created successfully at {new_repo.html_url}\")\n",
        "\n",
        "        # --- NEW: Programmatic check for template content ---\n",
        "        print(\"\\nWaiting for template files to be imported...\")\n",
        "        content_imported = False\n",
        "        while not content_imported:\n",
        "            try:\n",
        "                # Check for the existence of the main index file as a proxy for completion\n",
        "                new_repo.get_contents(\"docs/index.html\")\n",
        "                content_imported = True\n",
        "            except GithubException:\n",
        "                print(\"Waiting for template content...\", end=\"\\r\")\n",
        "                time.sleep(5)\n",
        "        print(\"\\nTemplate files have been successfully imported.\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "# --- 6. PREPARE YOUR GEOJSON DATA ---\n",
        "# This is done in a previous cell\n",
        "\n",
        "# --- 7. ADDING YOUR DATA TO THE REPOSITORY ---\n",
        "print(\"\\n--- Step 2: Adding your data to the repository ---\")\n",
        "# Create GeoJSON file content\n",
        "geojson_content = json.dumps(geojson_data, indent=2)\n",
        "geojson_commit_message = f\"Automated update of {GEOJSON_FILE_PATH}\"\n",
        "\n",
        "try:\n",
        "    contents = new_repo.get_contents(GEOJSON_FILE_PATH)\n",
        "    new_repo.update_file(\n",
        "        path=GEOJSON_FILE_PATH,\n",
        "        message=geojson_commit_message,\n",
        "        content=geojson_content,\n",
        "        sha=contents.sha\n",
        "    )\n",
        "    print(f\"Successfully updated {GEOJSON_FILE_PATH}.\")\n",
        "except GithubException as e:\n",
        "    if e.status == 404:\n",
        "        new_repo.create_file(\n",
        "            path=GEOJSON_FILE_PATH,\n",
        "            message=geojson_commit_message,\n",
        "            content=geojson_content\n",
        "        )\n",
        "        print(f\"Successfully created {GEOJSON_FILE_PATH}.\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "# Create or update the Peripleo config.json file\n",
        "config_data = {\n",
        "    \"initial_bounds\": geojson_data['bbox'],\n",
        "    \"map_style\": \"./map-style-OSM.json\",\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"name\": \"Disambiguation Test\",\n",
        "            \"format\": \"LINKED_PLACES\",\n",
        "            \"src\": \"./data/historical_data.geojson\",\n",
        "            \"attribution\": \"Leiden Workshop\"\n",
        "        }\n",
        "    ],\n",
        "    \"facets\": [\n",
        "        \"type\"\n",
        "    ],\n",
        "    \"link_icons\": [\n",
        "        { \"pattern\": \"maps.google.com\",  \"img\": \"./logos/maps.google.com.png\", \"label\": \"Google Maps\" },\n",
        "        { \"pattern\": \"www.geograph.org.uk\", \"img\": \"./logos/geograph.org.png\", \"label\": \"Geograph\" },\n",
        "        { \"pattern\": \"en.wikipedia.org\", \"img\": \"./logos/en.wikipedia.org.png\", \"label\": \"Wikipedia\" },\n",
        "        { \"pattern\": \"www.wikidata.org\", \"img\": None, \"label\": \"Wikidata\" },\n",
        "        { \"pattern\": \"www.geonames.org\", \"img\": None, \"label\": \"GeoNames\" },\n",
        "        { \"pattern\": \"sws.geonames.org\", \"img\": None, \"label\": \"GeoNames\" }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert the Python dictionary to a JSON string with indentation for readability\n",
        "config_content = json.dumps(config_data, indent=2)\n",
        "config_commit_message = f\"Automated update of {CONFIG_FILE_PATH}\"\n",
        "try:\n",
        "    contents = new_repo.get_contents(CONFIG_FILE_PATH)\n",
        "    new_repo.update_file(\n",
        "        path=CONFIG_FILE_PATH,\n",
        "        message=config_commit_message,\n",
        "        content=config_content,\n",
        "        sha=contents.sha\n",
        "    )\n",
        "    print(f\"Successfully updated {CONFIG_FILE_PATH}.\")\n",
        "except GithubException as e:\n",
        "    if e.status == 404:\n",
        "        new_repo.create_file(\n",
        "            path=CONFIG_FILE_PATH,\n",
        "            message=config_commit_message,\n",
        "            content=config_content\n",
        "        )\n",
        "        print(f\"Successfully created {CONFIG_FILE_PATH}.\")\n",
        "    else:\n",
        "        raise e\n",
        "\n",
        "\n",
        "# --- 8. ENABLE GITHUB PAGES ---\n",
        "print(\"\\n--- Step 3: Enabling GitHub Pages ---\")\n",
        "pages_url = f\"https://api.github.com/repos/{GITHUB_USERNAME}/{REPO_NAME}/pages\"\n",
        "pages_data = {\n",
        "    \"source\": {\n",
        "        \"branch\": \"main\",\n",
        "        \"path\": \"/docs\"\n",
        "    }\n",
        "}\n",
        "try:\n",
        "    response = requests.post(pages_url, headers=standard_headers, json=pages_data)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Wait for Pages to become active\n",
        "    pages_active = False\n",
        "    print(f\"You can check the build status here: https://github.com/{GITHUB_USERNAME}/{REPO_NAME}/actions\")\n",
        "    while not pages_active:\n",
        "        try:\n",
        "            pages_status_url = f\"https://api.github.com/repos/{GITHUB_USERNAME}/{REPO_NAME}/pages\"\n",
        "            pages_status = requests.get(pages_status_url, headers=standard_headers).json()\n",
        "            if pages_status.get('status') == 'built':\n",
        "                pages_active = True\n",
        "                print(\"\\nGitHub Pages enabled successfully.\")\n",
        "        except Exception:\n",
        "            pass # Keep waiting\n",
        "        print(\"Waiting for GitHub Pages to be provisioned...\", end=\"\\r\")\n",
        "        time.sleep(10)\n",
        "\n",
        "    print(f\"\\nDeployment process complete!\")\n",
        "    print(f\"Your repository is at: https://github.com/{GITHUB_USERNAME}/{REPO_NAME}\")\n",
        "    print(f\"Your Peripleo map should be available shortly at: {pages_status.get('html_url')}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error enabling GitHub Pages: {e}. You may need to enable it manually.\")"
      ],
      "metadata": {
        "id": "40TM0AVeiaKE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Map Data Download (optional)\n",
        "\n",
        "#@markdown Run the cell and then click the button which appears below to download a GeoJSON representation of the locations mentioned in your original CSV file.\n",
        "\n",
        "#@markdown GeoJSON is a standard format for representing geographic data with a simple structure of points, lines, and polygons.\n",
        "\n",
        "import json\n",
        "import base64\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Convert the GeoJSON object to a formatted string\n",
        "geojson_string = json.dumps(geojson_data, indent=2)\n",
        "\n",
        "# Encode the GeoJSON string to base64 for a data URI\n",
        "encoded_geojson = base64.b64encode(geojson_string.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "# HTML for a styled download button\n",
        "button_html = f\"\"\"\n",
        "<a href=\"data:application/json;charset=utf-8;base64,{encoded_geojson}\"\n",
        "   download=\"historical_data.geojson\"\n",
        "   style=\"\n",
        "       background-color: #4CAF50;\n",
        "       color: white;\n",
        "       padding: 12px 28px;\n",
        "       text-align: center;\n",
        "       text-decoration: none;\n",
        "       display: inline-block;\n",
        "       font-size: 16px;\n",
        "       margin: 6px 2px;\n",
        "       cursor: pointer;\n",
        "       border-radius: 8px;\n",
        "       border: none;\n",
        "       font-weight: bold;\n",
        "   \">\n",
        "    üì• Download Historical Data (GeoJSON)\n",
        "</a>\n",
        "\"\"\"\n",
        "\n",
        "# Display the button in Colab\n",
        "display(HTML(button_html))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gtmKVB7vCnJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}