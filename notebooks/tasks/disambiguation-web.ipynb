{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6a1c79",
   "metadata": {},
   "source": [
    "## Disambiguation\n",
    "\n",
    "In this notebook...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72869171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b14d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fb0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74853169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "\n",
    "def annotated_text_to_spacy_doc(text, nlp=None):\n",
    "    \"\"\"\n",
    "    Converts annotated text in format [Entity](LABEL) to a spaCy Doc with entity spans.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text with annotations like \"[Tom](PERSON) worked for [Microsoft](ORGANIZATION)\"\n",
    "        nlp (spacy.Language, optional): spaCy language model. If None, uses blank English model.\n",
    "    \n",
    "    Returns:\n",
    "        spacy.tokens.Doc: spaCy document with entity spans set\n",
    "        \n",
    "    Example:\n",
    "        >>> text = \"[Tom](PERSON) worked for [Microsoft](ORGANIZATION) in 2020 before he lived in [Rome](LOCATION).\"\n",
    "        >>> doc = annotated_text_to_spacy_doc(text)\n",
    "        >>> spacy.displacy.render(doc, style=\"ent\")\n",
    "    \"\"\"\n",
    "    if nlp is None:\n",
    "        nlp = spacy.blank(\"en\")\n",
    "    \n",
    "    # Pattern to match [text](LABEL) format\n",
    "    pattern = r'\\[([^\\]]+)\\]\\(([^)]+)\\)'\n",
    "    \n",
    "    # Parse the text to extract tokens and entity information\n",
    "    tokens = []\n",
    "    entity_spans = []  # List of (start_token_idx, end_token_idx, label)\n",
    "    custom_labels = set()\n",
    "    \n",
    "    # Split text by the pattern and process each part\n",
    "    last_end = 0\n",
    "    token_idx = 0\n",
    "    \n",
    "    for match in re.finditer(pattern, text):\n",
    "        # Add tokens before the entity\n",
    "        before_entity = text[last_end:match.start()]\n",
    "        if before_entity.strip():\n",
    "            # Tokenize the text before the entity\n",
    "            before_tokens = before_entity.split()\n",
    "            tokens.extend(before_tokens)\n",
    "            token_idx += len(before_tokens)\n",
    "        \n",
    "        # Add the entity tokens\n",
    "        entity_text = match.group(1)\n",
    "        entity_label = match.group(2)\n",
    "        custom_labels.add(entity_label)\n",
    "        \n",
    "        # Tokenize the entity text\n",
    "        entity_tokens = entity_text.split()\n",
    "        start_token_idx = token_idx\n",
    "        tokens.extend(entity_tokens)\n",
    "        token_idx += len(entity_tokens)\n",
    "        end_token_idx = token_idx\n",
    "        \n",
    "        # Store entity span information\n",
    "        entity_spans.append((start_token_idx, end_token_idx, entity_label))\n",
    "        \n",
    "        last_end = match.end()\n",
    "    \n",
    "    # Add any remaining tokens after the last entity\n",
    "    remaining = text[last_end:]\n",
    "    if remaining.strip():\n",
    "        remaining_tokens = remaining.split()\n",
    "        tokens.extend(remaining_tokens)\n",
    "    \n",
    "    # Add custom labels to the NLP model if they don't exist\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    for label in custom_labels:\n",
    "        ner.add_label(label)\n",
    "    \n",
    "    # Create spaces array (True for tokens that should have a space after them)\n",
    "    # Simple heuristic: all tokens except the last one get a space\n",
    "    spaces = [True] * len(tokens)\n",
    "    if tokens:\n",
    "        spaces[-1] = False\n",
    "    \n",
    "    # Create the Doc from tokens\n",
    "    doc = Doc(nlp.vocab, words=tokens, spaces=spaces)\n",
    "    \n",
    "    # Create entity spans\n",
    "    entities = []\n",
    "    for start_idx, end_idx, label in entity_spans:\n",
    "        if start_idx < len(doc) and end_idx <= len(doc):\n",
    "            span = Span(doc, start_idx, end_idx, label=label)\n",
    "            entities.append(span)\n",
    "    \n",
    "    # Set entities on the document\n",
    "    doc.ents = entities\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "def visualize_annotated_text(text, nlp=None, style=\"ent\", jupyter=True):\n",
    "    \"\"\"\n",
    "    Convenience function to convert annotated text and visualize it with displaCy.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text with annotations like \"[Tom](PERSON) worked for [Microsoft](ORGANIZATION)\"\n",
    "        nlp (spacy.Language, optional): spaCy language model. If None, uses blank English model.\n",
    "        style (str): displaCy style (\"ent\" or \"dep\")\n",
    "        jupyter (bool): Whether to render for Jupyter notebook\n",
    "    \n",
    "    Returns:\n",
    "        Rendered visualization (HTML string if not in Jupyter)\n",
    "    \"\"\"\n",
    "    doc = annotated_text_to_spacy_doc(text, nlp)\n",
    "    \n",
    "    try:\n",
    "        import spacy\n",
    "        return spacy.displacy.render(doc, style=style, jupyter=jupyter)\n",
    "    except ImportError:\n",
    "        print(\"spaCy not installed. Please install with: pip install spacy\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626edad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e86d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "TEXT = \"They marched from [Alexandria](LOCATION) through [Memphis](LOCATION) via the [Nile](LOCATION) to [Thebes](LOCATION).\"\n",
    "ENTITY_TO_IDENTIFY = \"Memphis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94acadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Query the web to identify this entity in Wikidata.\n",
    "\n",
    "{entity}\n",
    "\n",
    "It is within the context of the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Only return the JSON output, nothing else. Do so with the following schema:\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    entity_text: str\n",
    "    label: str\n",
    "    wikidata_id: str\n",
    "    sources: list[str]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f4ebaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = prompt.format(entity=ENTITY_TO_IDENTIFY, text=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bac810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query the web to identify this entity in Wikidata.\n",
      "\n",
      "Memphis\n",
      "\n",
      "It is within the context of the following text:\n",
      "\n",
      "They marched from [Alexandria](LOCATION) through [Memphis](LOCATION) via the [Nile](LOCATION) to [Thebes](LOCATION).\n",
      "\n",
      "Only return the JSON output, nothing else. Do so with the following schema:\n",
      "\n",
      "class Entity(BaseModel):\n",
      "    entity_text: str\n",
      "    label: str\n",
      "    wikidata_id: str\n",
      "    sources: list[str]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be66c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"web_search\",\n",
    "}],\n",
    "    input=formatted_prompt,\n",
    ")\n",
    "\n",
    "output_text = response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ea07a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"entity_text\": \"Memphis\",\n",
      "  \"label\": \"Memphis\",\n",
      "  \"wikidata_id\": \"Q5715\",\n",
      "  \"sources\": [\n",
      "    \"Wikidata entry for ancient capital of Inebu-hedj, Egypt\",\n",
      "    \"UNT Digital Library ”Egypt – Giza Governorate – Memphis\\\" for Wikidata link Q5715\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_text': 'Memphis', 'label': 'Memphis', 'wikidata_id': 'Q5715', 'sources': ['Wikidata entry for ancient capital of Inebu-hedj, Egypt', 'UNT Digital Library ”Egypt – Giza Governorate – Memphis\" for Wikidata link Q5715']}\n"
     ]
    }
   ],
   "source": [
    "def parse_json_with_sources(text):\n",
    "    json_data = text.split(\"```json\")[1]\n",
    "    json_data, sources = json_data.split(\"```\")\n",
    "    json_data = json.loads(json_data)\n",
    "    return json_sdata, sources\n",
    "\n",
    "json_output, sources = parse_json_with_sources(output_text)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50d0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603d5ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They marched from [Alexandria](LOCATION) through [Memphis](LOCATION) via the [Nile](LOCATION) to [Thebes](LOCATION).'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0912 09:27:14.353000 43069 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8622fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = annotated_text_to_spacy_doc(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d3aaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">They marched from \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alexandria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       " through \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Memphis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       " via the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nile\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thebes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c9a172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ents = []\n",
    "for ent in doc.ents:\n",
    "    if ent.text == ENTITY_TO_IDENTIFY:\n",
    "        output_ents.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": f'{ent.label_} <a href=\"https://www.wikidata.org/wiki/{json_output[\"wikidata_id\"]}\">{json_output[\"wikidata_id\"]}</a>'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83f8ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">They marched from Alexandria through \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Memphis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION <a href=\"https://www.wikidata.org/wiki/Q5715\">Q5715</a></span>\n",
       "</mark>\n",
       " via the Nile to Thebes .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dic_ents = {\n",
    "    \"text\": doc.text,\n",
    "    \"ents\": output_ents,\n",
    "    \"title\": None\n",
    "}\n",
    "\n",
    "displacy.render(dic_ents, manual=True, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265856e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7112b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gliner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
