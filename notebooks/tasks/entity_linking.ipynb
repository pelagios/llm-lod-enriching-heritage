{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bab1756-a7f0-46cb-861b-c3e90fea3ba8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pelagios/llm-lod-enriching-heritage/blob/main/notebooks/tasks/entity_linking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc201a-4ecd-4714-be9e-2b35a1f6922d",
   "metadata": {},
   "source": [
    "# Entity linking\n",
    "\n",
    "This notebook links the entities found in the previous steps (NER, Disambiguation) to the artefacts\n",
    "\n",
    "### Rationale\n",
    "\n",
    "Making explicit the relations between the named entities helps us to better understand the data. In the context of museum artefact descriptions there are two major types of relations: relation between named entities among each other and relations between named entities and the artefacts. In the main data files used for testing the software, from the Egyptian Museum of Turin, the first group of relations is quite rare. Therefore we focus on finding relations/links between artefacts and the named entities in their description texts.\n",
    "\n",
    "We use large language models (LLMs) to derive the relations. To make the task manageable, we have restricted the relations to six types:\n",
    "\n",
    "1. the artefact represents the entity\n",
    "2. the entity represents the geographical context of the artefact\n",
    "3. the entity represents the historical context of the artefact\n",
    "4. the entity is related to an object or person represented in the artefact\n",
    "5. the entity is a previous owner of the artefact\n",
    "6. the entity is mentioned for another reason\n",
    "\n",
    "We include the definitions of these types in the prompt sent to the LLMs and ask them to select the best matching one. We offer each entity to the LLMs separately.\n",
    "\n",
    "### Processing overview\n",
    "\n",
    "The process consists of the following steps:\n",
    "\n",
    "1. Import required software libraries: We start with importing required software libraries\n",
    "2. Read the text that requires processing: Next we obtain the input text from the Disambiguation notebook\n",
    "3. Linking: The text is sent to GPT with a prompt that instructs it to select the best type for the link between the artefact and the entity\n",
    "4. Linking visualization: The link type is displayed in text with colour-coded entities\n",
    "5. Save results: Save the results of the linking process for future processing\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This notebook depends on three files:\n",
    "\n",
    "* utils.py: helper functions\n",
    "* output_disambiguation_ba25101ddbe8830789bfdfdb3a5ba6312d6853e6.json: output file of disambiguation task\n",
    "* linking_cache.json: context-dependent cache of linking analysis performed earlier\n",
    "\n",
    "Please make sure they are available in this folder so that the notebook can run smoothly. You can download them from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec9644-9cea-4ea5-9396-a9c039c5f538",
   "metadata": {},
   "source": [
    "## 1. Import required software libraries\n",
    "\n",
    "Entity linking requires importing some standard software libraries. This step may take some time when run for the first time but in successive runs it will be a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f735231-ad73-4158-aefe-4935532f3a90",
   "metadata": {},
   "source": [
    "First we import standard libraries which should always be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd95fe3-bc47-413d-9e37-274820524903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e1d2b-44dd-4931-a9b3-69f047c04414",
   "metadata": {},
   "source": [
    "Next we import packages which may require installation on this device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ef6754-ccb7-40dc-ad6f-4064b93b1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = utils.safe_import(\"openai\")\n",
    "pd = utils.safe_import(\"pandas\")\n",
    "pydantic = utils.safe_import(\"pydantic\")\n",
    "spacy = utils.safe_import(\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b231a-cfa4-4219-a3e1-424b4d6bafd9",
   "metadata": {},
   "source": [
    "Finally we set settings required for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1471a3c9-2f1c-45ca-aa3c-7c47cbb12f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_colab = utils.check_google_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f98f99-340f-4e2d-8587-796e9fc5172a",
   "metadata": {},
   "source": [
    "## 2. Read the texts that require processing\n",
    "\n",
    "The texts should have been processed by the `ner.ipynb` notebook. The file read here is an output file of the `disambiguation-candidates.ipynb` notebook which in turn processed the `ner.ipynb` output. We read the texts and the associated metadata and show the first text with its entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a5f46e-2cd4-4761-9ab9-4e64259dc259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_cleaned': 'Statuette of the god Anubis. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115', 'entities': [{'text': 'Anubis', 'label': 'PERSON', 'start_char': 21, 'end_char': 27, 'wikidata_id': {'id': 'Q47534', 'description': 'Egyptian deity of mummification and the afterlife, usually depicted as a man with a canine head', 'model': 'gpt-4o-mini'}}]}\n"
     ]
    }
   ],
   "source": [
    "infile_name = \"output_disambiguation_ba25101ddbe8830789bfdfdb3a5ba6312d6853e6.json\"\n",
    "\n",
    "with open(infile_name, \"r\") as infile:\n",
    "    texts_input = json.load(infile)\n",
    "    infile.close()\n",
    "print({\"text_cleaned\": texts_input[0][\"text_cleaned\"], \n",
    "       \"entities\": texts_input[0][\"entities\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c9ca7-bb1c-4c94-afa0-1a0016def39d",
   "metadata": {},
   "source": [
    "## 3. Link entities with GPT\n",
    "\n",
    "We link entities to the artefacts by sending a prompt with each entity text, the context text and six candidate link types to an LLM. We ask the LLM to return the id associated with the type that best matches the type of link between the entity and the artefact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc12725-3003-4c45-a6da-55dd3139f281",
   "metadata": {},
   "source": [
    "First we define three helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5504175d-8caf-4917-b181-5f449cc7f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linking_prompt(entity, text):\n",
    "    \"\"\"Create an LLM prompt, given a text and target labels and return it\"\"\"\n",
    "    return f\"\"\"\n",
    "Considering the following description of a museum artefact:\n",
    "\n",
    "{text}\n",
    "\n",
    "retrieve the relationship between this artefact and the following named entity, mentioned in the description:\n",
    "\n",
    "{entity}\n",
    "\n",
    "Please answer the following question: Why is this entity mentioned in the description? Please select your answer from the following options:\n",
    "\n",
    "1. the artefact represents the entity\n",
    "2. the entity represents the geographical context of the artefact\n",
    "3. the entity represents the historical context of the artefact\n",
    "4. the entity is related to an object or person represented in the artefact\n",
    "5. the entity is a previous owner of the artefact\n",
    "6. the entity is mentioned for another reason\n",
    "\n",
    "Answer only with a number. If you choose for option 6, you  may add a clarification text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd0b672-7c62-4cdc-9e92-80c1a6f2f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linking_data_to_texts_input(texts_input, entities):\n",
    "    \"\"\"Insert the retrieved linking data into the variable text_inputs and return it\"\"\"\n",
    "    entities_per_text = {}\n",
    "    for entity in entities:\n",
    "        if entity[\"text_id\"] not in entities_per_text:\n",
    "            entities_per_text[entity[\"text_id\"]] = {}\n",
    "        entities_per_text[entity[\"text_id\"]][entity[\"entity_text\"]] = entity\n",
    "    for text_id, text in enumerate(texts_input):\n",
    "        for entity in text[\"entities\"]:\n",
    "            if text_id in entities_per_text and entity[\"text\"] in entities_per_text[text_id]:\n",
    "                entity[\"link\"] = entities_per_text[text_id][entity[\"text\"]][\"link\"]\n",
    "    return texts_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e34a6d1-e14f-4230-8a1e-55a068c0c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKING_CACHE_FILE = \"linking_cache.json\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "def openai_link_suggestion(model, texts_input):\n",
    "    openai_api_key = utils.get_openai_api_key()\n",
    "    openai_client = utils.connect_to_openai(openai_api_key)\n",
    "    entities = utils.extract_entities_from_ner_input(texts_input)\n",
    "    linking_cache = utils.read_json_file(LINKING_CACHE_FILE)\n",
    "    for entity in entities:\n",
    "        if (entity[\"entity_text\"] in linking_cache and \n",
    "            entity[\"text\"] in linking_cache[entity[\"entity_text\"]] and\n",
    "            model in linking_cache[entity[\"entity_text\"]][entity[\"text\"]]):\n",
    "            utils.squeal(f\"Retrieving entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} from cache\")\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model]\n",
    "        else:\n",
    "            utils.squeal(f\"Sending entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} to GPT\")\n",
    "            time.sleep(1)\n",
    "            prompt = make_linking_prompt(entity[\"entity_text\"], entity[\"text\"])\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = utils.process_text_with_gpt(openai_client, model, prompt)\n",
    "            if entity[\"entity_text\"] not in linking_cache:\n",
    "                linking_cache[entity[\"entity_text\"]] = {}\n",
    "            if entity[\"text\"] not in linking_cache[entity[\"entity_text\"]]:\n",
    "                linking_cache[entity[\"entity_text\"]][entity[\"text\"]] = {}\n",
    "            linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model] = entity[\"link\"][model]\n",
    "    print(\"Finished processing\")\n",
    "    utils.save_data_to_json_file(linking_cache, file_name=LINKING_CACHE_FILE, in_colab=in_colab)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c566a67-36cb-4806-8fea-217a72f31b7e",
   "metadata": {},
   "source": [
    "Next, we call GPT to suggest the types of links between the entities and the artefact. We call the GPT separately for each unique entity. In case the model used already predicted an entity, we used the link type stored in the cache. The links are collected in the variable `entities` and are later stored in the variable `texts_output`. We show the first item of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30bd265f-5c55-42b4-9f06-b603a024e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving entity \"Bagnani\" of text 100 from cache\n",
      "Finished processing\n",
      "️✅ Saved data to file linking_cache_123dc2598ed9928793036410b9aa30be38b190de.json\n",
      "{'text_cleaned': 'Statuette of the god Anubis. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115', 'entities': [{'entity_text': 'Anubis', 'wikidata_id': 'Q47534', 'link': '1'}]}\n"
     ]
    }
   ],
   "source": [
    "entities = openai_link_suggestion(model, texts_input)\n",
    "texts_output = add_linking_data_to_texts_input(texts_input, entities)\n",
    "print({\"text_cleaned\": texts_output[0][\"text_cleaned\"],\n",
    "       \"entities\": [{\"entity_text\": entity[\"text\"], \n",
    "                     \"wikidata_id\": entity[\"wikidata_id\"][\"id\"], \n",
    "                     \"link\": list(entity[\"link\"].values())[0]} for entity in texts_output[0][\"entities\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae9406-2049-4bbe-bed2-33bf5d1ee4d1",
   "metadata": {},
   "source": [
    "## 4. Linking visualization\n",
    "\n",
    "We visualize the results of the linking process by displaying the numeric linking code in superscript next to the entity in its context. Please note that the six numeric codes represent the relations between the entity and the artefact and stand for the following:\n",
    "\n",
    "1. the artefact represents the entity\n",
    "2. the entity represents the geographical context of the artefact\n",
    "3. the entity represents the historical context of the artefact\n",
    "4. the entity is related to an object or person represented in the artefact\n",
    "5. the entity is a previous owner of the artefact\n",
    "6. the entity is mentioned for another reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460020ff-a77c-45ad-a9c5-456f9608e074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Statuette of the god <span style=\"border: 1px solid black; color: red;\">Anubis</span><sup>Q47534,1</sup>. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"border: 1px solid black; color: red;\">Sekhmet</span><sup>Q146104,1</sup> was a goddess. <span style=\"border: 1px solid black; color: green;\">Thebes</span><sup>Q101583,2</sup> is referenced. The object is made of granodiorite and belongs to the Drovetti collection (1824). It dates back to the New Kingdom, 18th Dynasty, during the reign of <span style=\"border: 1px solid black; color: red;\">Amenhotep III</span><sup>Q42606,1</sup> (1390-1353 BC)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Statuette of the goddess <span style=\"border: 1px solid black; color: red;\">Bastet</span><sup>Q129106,1</sup>. Bronze. Late Period (722-332 BC).. <span style=\"border: 1px solid black; color: red;\">Drovetti</span><sup>Q822895,4</sup> collection (1824). C. 271"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text_id, text in enumerate(texts_output):\n",
    "    if text_id < 3:\n",
    "        display(HTML(utils.mark_entities_in_text(text[\"text_llm_output\"], text[\"entities\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cb9e1-87d8-44ac-af29-051df6d10ba5",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "We save the results in a json file. The helper function used for this is defined in the file `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bad32c-1c93-4d99-b6a1-9896acda1676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "️✅ Saved data to file output_linking.ipynb\n"
     ]
    }
   ],
   "source": [
    "utils.save_data_to_json_file(texts_output, file_name=\"output_linking.ipynb\", in_colab=in_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb00f7b-dcf6-4b0b-b756-aa8b39494958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
