{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bab1756-a7f0-46cb-861b-c3e90fea3ba8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pelagios/llm-lod-enriching-heritage/blob/main/notebooks/tasks/entity_linking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc201a-4ecd-4714-be9e-2b35a1f6922d",
   "metadata": {},
   "source": [
    "# Entity linking\n",
    "\n",
    "This notebook links the entities found in the previous steps (NER, Disambiguation) to the artefacts\n",
    "\n",
    "### Rationale\n",
    "\n",
    "Making explicit the relations between the named entities helps us to better understand the data. In the context of museum artefact descriptions there are two major types of relations: relation between named entities among each other and relations between named entities and the artefacts. In the main data files used for testing the software, from the Egyptian Museum of Turin, the first group of relations is quite rare. Therefore we focus on finding relations/links between artefacts and the named entities in their description texts.\n",
    "\n",
    "We use large language models (LLMs) to derive the relations. To make the task manageable, we have restricted the relations to eleven types:\n",
    "\n",
    "1. the entity is a person depicted on or by the artefact\n",
    "2. the entity is a person that created the artefact\n",
    "3. the entity is a person that discovered the artefact\n",
    "4. the entity is a person that owned the artefact\n",
    "5. the entity is a person in power during the period of the creation of the artefact\n",
    "6. the entity is a location depicted on or by the artefact\n",
    "7. the entity is a location where the artefact was created\n",
    "8. the entity is a location where the artefact was produced\n",
    "9. the entity is a location where the artefact was discovered\n",
    "10. the entity is the artefact's current location\n",
    "11. other entity type or other relation between entity and artefact\n",
    "\n",
    "We include the definitions of these types in the prompt sent to the LLMs and ask them to select the best matching one. We offer each entity to the LLMs separately.\n",
    "\n",
    "### Processing overview\n",
    "\n",
    "The process consists of the following steps:\n",
    "\n",
    "1. Import required software libraries: We start with importing required software libraries\n",
    "2. Read the text that requires processing: Next we obtain the input text from the Disambiguation notebook\n",
    "3. Linking: The text is sent to GPT with a prompt that instructs it to select the best type for the link between the artefact and the entity\n",
    "4. Linking visualization: The link type is displayed in text with colour-coded entities\n",
    "5. Save results: Save the results of the linking process for future processing\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This notebook depends on three files:\n",
    "\n",
    "* utils.py: helper functions\n",
    "* output_disambiguation_ba25101ddbe8830789bfdfdb3a5ba6312d6853e6.json: output file of disambiguation task\n",
    "* linking_cache.json: context-dependent cache of linking analysis performed earlier\n",
    "\n",
    "Please make sure they are available in this folder so that the notebook can run smoothly. You can download them from Github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec9644-9cea-4ea5-9396-a9c039c5f538",
   "metadata": {},
   "source": [
    "## 1. Import required software libraries\n",
    "\n",
    "Entity linking requires importing some standard software libraries. This step may take some time when run for the first time but in successive runs it will be a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12c27a-f315-41c9-8889-24ccb2958cc5",
   "metadata": {},
   "source": [
    "We start with checking if the notebook is running on Google Colab. If that is the case, we need to connect to the notebook's environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5e2053-c423-40ab-99bb-c0e280acf97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google Colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_notebook_environment_on_colab():\n",
    "    \"\"\"Test if run on Colab, if so test if environment is available, if not install it\"\"\"\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        try:\n",
    "            os.chdir(\"/content/llm-lod-enriching-heritage/notebooks/tasks\")\n",
    "            print(\"Found notebook environment\")\n",
    "        except:\n",
    "            print(\"notebook environment not found, installing...\")\n",
    "            !git clone https://github.com/pelagios/llm-lod-enriching-heritage.git\n",
    "            os.chdir(\"/content/llm-lod-enriching-heritage/notebooks/tasks\")\n",
    "    except:\n",
    "        print(\"Not running on Google Colab\")\n",
    "\n",
    "check_notebook_environment_on_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f735231-ad73-4158-aefe-4935532f3a90",
   "metadata": {},
   "source": [
    "Next we import standard libraries which should always be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd95fe3-bc47-413d-9e37-274820524903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e1d2b-44dd-4931-a9b3-69f047c04414",
   "metadata": {},
   "source": [
    "Next we import packages which may require installation on this device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ef6754-ccb7-40dc-ad6f-4064b93b1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = utils.safe_import(\"openai\")\n",
    "pd = utils.safe_import(\"pandas\")\n",
    "pydantic = utils.safe_import(\"pydantic\")\n",
    "spacy = utils.safe_import(\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b231a-cfa4-4219-a3e1-424b4d6bafd9",
   "metadata": {},
   "source": [
    "Finally we set settings required for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1471a3c9-2f1c-45ca-aa3c-7c47cbb12f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_colab = utils.check_google_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0c00f-e1d0-4936-b028-b672a361f552",
   "metadata": {},
   "source": [
    "These two helper functions are needed in different sections, we define them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5504175d-8caf-4917-b181-5f449cc7f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"\"\"extracted from records of objects in the collection of \n",
    "             the Egyptian museum, Torino, the Museo Egizio – Torino\"\"\"\n",
    "\n",
    "def make_linking_prompt(entity, text):\n",
    "    \"\"\"Create an LLM prompt, given a text and target labels and return it\"\"\"\n",
    "    return f\"\"\"\n",
    "Considering the following description of a museum artefact {CONTEXT}:\n",
    "\n",
    "{text}\n",
    "\n",
    "Retrieve the relationship between this artefact and the following named entity, \n",
    "mentioned in the description:\n",
    "\n",
    "{entity}\n",
    "\n",
    "Please answer the following question: Why is this entity mentioned in the description? \n",
    "Please select your answer from the following options:\n",
    "\n",
    "1. the entity is a person depicted on or by the artefact\n",
    "2. the entity is a person that created the artefact\n",
    "3. the entity is a person that discovered the artefact\n",
    "4. the entity is a person that owned the artefact\n",
    "5. the entity is a person in power during the period of the creation of the artefact\n",
    "6. the entity is a location depicted on or by the artefact\n",
    "7. the entity is a location where the artefact was created\n",
    "8. the entity is a location where the artefact was produced\n",
    "9. the entity is a location where the artefact was discovered\n",
    "10. the entity is the artefact's current location\n",
    "11. other entity type or other relation between entity and artefact\n",
    "\n",
    "Answer only with a number. If you choose for option 11, you  may add a clarification text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd0b672-7c62-4cdc-9e92-80c1a6f2f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linking_data_to_texts_input(texts_input, entities):\n",
    "    \"\"\"Insert the retrieved linking data into the variable text_inputs and return it\"\"\"\n",
    "    entities_per_text = {}\n",
    "    for entity in entities:\n",
    "        if entity[\"text_id\"] not in entities_per_text:\n",
    "            entities_per_text[entity[\"text_id\"]] = {}\n",
    "        entities_per_text[entity[\"text_id\"]][entity[\"entity_text\"]] = entity\n",
    "    for text_id, text in enumerate(texts_input):\n",
    "        for entity in text[\"entities\"]:\n",
    "            if text_id in entities_per_text and entity[\"text\"] in entities_per_text[text_id]:\n",
    "                entity[\"link\"] = entities_per_text[text_id][entity[\"text\"]][\"link\"]\n",
    "    return texts_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f98f99-340f-4e2d-8587-796e9fc5172a",
   "metadata": {},
   "source": [
    "## 2. Read the texts that require processing\n",
    "\n",
    "The texts should have been processed by the `ner.ipynb` notebook. The file read here is an output file of the `disambiguation-candidates.ipynb` notebook which in turn processed the `ner.ipynb` output. We read the texts and the associated metadata and show the first text with its entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a5f46e-2cd4-4761-9ab9-4e64259dc259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_cleaned': 'Statuette of the god Anubis. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115', 'entities': [{'text': 'Anubis', 'label': 'PERSON', 'start_char': 21, 'end_char': 27, 'wikidata_id': {'id': 'Q47534', 'description': 'Egyptian deity of mummification and the afterlife, usually depicted as a man with a canine head', 'model': 'gpt-4o-mini'}}]}\n"
     ]
    }
   ],
   "source": [
    "infile_name = \"output_disambiguation_ba25101ddbe8830789bfdfdb3a5ba6312d6853e6.json\"\n",
    "\n",
    "with open(infile_name, \"r\") as infile:\n",
    "    texts_input = json.load(infile)\n",
    "    infile.close()\n",
    "print({\"text_cleaned\": texts_input[0][\"text_cleaned\"], \n",
    "       \"entities\": texts_input[0][\"entities\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c9ca7-bb1c-4c94-afa0-1a0016def39d",
   "metadata": {},
   "source": [
    "## 3. Link entities with GPT\n",
    "\n",
    "We link entities to the artefacts by sending a prompt with each entity text, the context text and six candidate link types to an LLM. We ask the LLM to return the id associated with the type that best matches the type of link between the entity and the artefact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc12725-3003-4c45-a6da-55dd3139f281",
   "metadata": {},
   "source": [
    "First we define three helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e34a6d1-e14f-4230-8a1e-55a068c0c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKING_CACHE_FILE = \"linking_cache.json\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "def openai_link_suggestion(model, texts_input):\n",
    "    entities = utils.extract_entities_from_ner_input(texts_input)\n",
    "    linking_cache = utils.read_json_file(LINKING_CACHE_FILE)\n",
    "    for entity in entities:\n",
    "        if (entity[\"entity_text\"] in linking_cache and \n",
    "            entity[\"text\"] in linking_cache[entity[\"entity_text\"]] and\n",
    "            model in linking_cache[entity[\"entity_text\"]][entity[\"text\"]]):\n",
    "            utils.squeal(f\"Retrieving entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} from cache\")\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model]\n",
    "        else:\n",
    "            if \"openai_client\" not in vars():\n",
    "                openai_api_key = utils.get_openai_api_key()\n",
    "                openai_client = utils.connect_to_openai(openai_api_key)                \n",
    "            utils.squeal(f\"Sending entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} to GPT\")\n",
    "            time.sleep(1)\n",
    "            prompt = make_linking_prompt(entity[\"entity_text\"], entity[\"text\"])\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = utils.process_text_with_gpt(openai_client, model, prompt)\n",
    "            if entity[\"entity_text\"] not in linking_cache:\n",
    "                linking_cache[entity[\"entity_text\"]] = {}\n",
    "            if entity[\"text\"] not in linking_cache[entity[\"entity_text\"]]:\n",
    "                linking_cache[entity[\"entity_text\"]][entity[\"text\"]] = {}\n",
    "            linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model] = entity[\"link\"][model]\n",
    "            utils.write_json_file(LINKING_CACHE_FILE, linking_cache)\n",
    "    print(\"Finished processing\")\n",
    "    utils.save_data_to_json_file(linking_cache, file_name=LINKING_CACHE_FILE, in_colab=in_colab)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c566a67-36cb-4806-8fea-217a72f31b7e",
   "metadata": {},
   "source": [
    "Next, we call GPT to suggest the types of links between the entities and the artefact. We call the GPT separately for each unique entity. In case the model used already predicted an entity, we used the link type stored in the cache. The links are collected in the variable `entities` and are later stored in the variable `texts_output`. Change the value of the MAX_PROCESSED variable if you do not want all texts to be processed by the LLM. We show the first item of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bd265f-5c55-42b4-9f06-b603a024e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving entity \"Bagnani\" of text 100 from cache\n",
      "Finished processing\n",
      "️✅ Saved data to file linking_cache_7d1cb217b7ded2bec61ee23fc7daae71fde7b271.json\n",
      "{'text_cleaned': 'Statuette of the god Anubis. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115', 'entities': [{'entity_text': 'Anubis', 'wikidata_id': 'Q47534', 'link': '1'}]}\n"
     ]
    }
   ],
   "source": [
    "MAX_PROCESSED = 100\n",
    "\n",
    "entities = openai_link_suggestion(model, texts_input)\n",
    "texts_output = add_linking_data_to_texts_input(texts_input[:MAX_PROCESSED], entities)\n",
    "print({\"text_cleaned\": texts_output[0][\"text_cleaned\"],\n",
    "       \"entities\": [{\"entity_text\": entity[\"text\"], \n",
    "                     \"wikidata_id\": entity[\"wikidata_id\"][\"id\"], \n",
    "                     \"link\": list(entity[\"link\"].values())[0]} for entity in texts_output[0][\"entities\"]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae9406-2049-4bbe-bed2-33bf5d1ee4d1",
   "metadata": {},
   "source": [
    "## 4. Linking visualization\n",
    "\n",
    "We visualize the results of the linking process by displaying the numeric linking code in superscript next to the entity in its context. Please note that the six numeric codes represent the relations between the entity and the artefact and stand for the following:\n",
    "\n",
    "1. the entity is a person depicted on or by the artefact\n",
    "2. the entity is a person that created the artefact\n",
    "3. the entity is a person that discovered the artefact\n",
    "4. the entity is a person that owned the artefact\n",
    "5. the entity is a person in power during the period of the creation of the artefact\n",
    "6. the entity is a location depicted on or by the artefact\n",
    "7. the entity is a location where the artefact was created\n",
    "8. the entity is a location where the artefact was produced\n",
    "9. the entity is a location where the artefact was discovered\n",
    "10. the entity is the artefact's current location\n",
    "11. other entity type or other relation between entity and artefact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460020ff-a77c-45ad-a9c5-456f9608e074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Statuette of the god <span style=\"border: 1px solid black; color: red;\">Anubis</span><sup>Q47534,1</sup>. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"border: 1px solid black; color: red;\">Sekhmet</span><sup>Q146104,1</sup> was a goddess. <span style=\"border: 1px solid black; color: green;\">Thebes</span><sup>Q101583,7</sup> is referenced. The object is made of granodiorite and belongs to the Drovetti collection (1824). It dates back to the New Kingdom, 18th Dynasty, during the reign of <span style=\"border: 1px solid black; color: red;\">Amenhotep III</span><sup>Q42606,5</sup> (1390-1353 BC)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Statuette of the goddess <span style=\"border: 1px solid black; color: red;\">Bastet</span><sup>Q129106,1</sup>. Bronze. Late Period (722-332 BC).. <span style=\"border: 1px solid black; color: red;\">Drovetti</span><sup>Q822895,4</sup> collection (1824). C. 271"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text_id, text in enumerate(texts_output):\n",
    "    if text_id < 3:\n",
    "        display(HTML(utils.mark_entities_in_text(text[\"text_llm_output\"], text[\"entities\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cb9e1-87d8-44ac-af29-051df6d10ba5",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "We save the results in a json file. The helper function used for this is defined in the file `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09bad32c-1c93-4d99-b6a1-9896acda1676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "️✅ Saved data to file output_linking_34e26bfd19c837e400a5fcb214cd1e7a25304a12.json\n"
     ]
    }
   ],
   "source": [
    "utils.save_data_to_json_file(texts_output, file_name=\"output_linking.json\", in_colab=in_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dec570-a51e-4822-8e14-50dbfc2bea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "️✅ Saved data to file entities_table.csv\n"
     ]
    }
   ],
   "source": [
    "utils.save_entities_as_table(\"entities_table.csv\", texts_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460091a2-7b72-49fa-9b11-cba73a5ad1f7",
   "metadata": {},
   "source": [
    "## 6. Alternatives for entity linking\n",
    "\n",
    "Here we define some alternatives for disambiguation, for example if you do not have an OpenAI API key or if you do not want to share your data with OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954dc941-21b3-434e-8853-402c55952a47",
   "metadata": {},
   "source": [
    "### 6.1. Disambiguate entities with Qwen\n",
    "\n",
    "Here we use [Qwen](https://en.wikipedia.org/wiki/Qwen), a locally-run model developed by the company Alibaba. The model has hardware requirements which your computer may not satisfy: it needs a GPU and about 12 gigabytes of memory. When running this model on Google Colab, it is recommended to use the runtime environment `T4 GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a56e8-a3ca-4247-a9d4-70d0a7341662",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKING_CACHE_FILE = \"linking_cache.json\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "def ollama_link_suggestion(model, texts_input):\n",
    "    entities = utils.extract_entities_from_ner_input(texts_input)\n",
    "    linking_cache = utils.read_json_file(LINKING_CACHE_FILE)\n",
    "    for entity in entities:\n",
    "        if (entity[\"entity_text\"] in linking_cache and \n",
    "            entity[\"text\"] in linking_cache[entity[\"entity_text\"]] and\n",
    "            model in linking_cache[entity[\"entity_text\"]][entity[\"text\"]]):\n",
    "            utils.squeal(f\"Retrieving entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} from cache\")\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model]\n",
    "        else:\n",
    "            utils.squeal(f\"Sending entity \\\"{entity['entity_text']}\\\" of text {entity['text_id'] + 1} to GPT\")\n",
    "            if \"ollama\" in sys.modules:\n",
    "                ollama = utils.importlib.import_module(\"ollama\")\n",
    "            else:\n",
    "                ollama = utils.import_ollama_module()\n",
    "            time.sleep(1)\n",
    "            prompt = make_linking_prompt(entity[\"entity_text\"], entity[\"text\"])\n",
    "            if \"link\" not in entity: entity[\"link\"] = {}\n",
    "            entity[\"link\"][model] = utils.process_text_with_ollama(model, prompt, ollama)\n",
    "            if entity[\"entity_text\"] not in linking_cache:\n",
    "                linking_cache[entity[\"entity_text\"]] = {}\n",
    "            if entity[\"text\"] not in linking_cache[entity[\"entity_text\"]]:\n",
    "                linking_cache[entity[\"entity_text\"]][entity[\"text\"]] = {}\n",
    "            linking_cache[entity[\"entity_text\"]][entity[\"text\"]][model] = entity[\"link\"][model]\n",
    "            utils.write_json_file(LINKING_CACHE_FILE, linking_cache)\n",
    "    print(\"Finished processing\")\n",
    "    utils.save_data_to_json_file(linking_cache, file_name=LINKING_CACHE_FILE, in_colab=in_colab)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10495a0d-cf81-4628-8a6d-c03453806f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROCESSED = 100\n",
    "\n",
    "entities = ollama_link_suggestion(model, texts_input)\n",
    "texts_output = add_linking_data_to_texts_input(texts_input[:MAX_PROCESSED], entities)\n",
    "print({\"text_cleaned\": texts_output[0][\"text_cleaned\"],\n",
    "       \"entities\": [{\"entity_text\": entity[\"text\"], \n",
    "                     \"wikidata_id\": entity[\"wikidata_id\"][\"id\"], \n",
    "                     \"link\": list(entity[\"link\"].values())[0]} for entity in texts_output[0][\"entities\"]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f7596-48bc-42f9-82fc-31968655c125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
