{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30cbd04-00d9-4fd1-8a93-fb2b466d319c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/pelagios/llm-lod-enriching-heritage/blob/main/notebooks/tasks/ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d2026",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task that involves identifying and classifying named entities (like people, places, organizations) within text. For example, in the sentence \"Shakespeare wrote Romeo and Juliet in London\", a NER system would identify \"Shakespeare\" as a person, \"Romeo and Juliet\" as a work of art, and \"London\" as a location. NER is crucial for extracting structured information from unstructured text, making it valuable for tasks like information retrieval, question answering, and metadata enrichment. In this notebook, we'll explore how to perform NER using both traditional NLP approaches and modern Large Language Models.\n",
    "\n",
    "### Rationale\n",
    "\n",
    "This notebook demonstrates how to use OpenAI's GPT models to perform Named Entity Recognition (NER) by converting input text into annotated markdown format. Rather than using traditional NLP libraries, we leverage a Large Language Model's natural language understanding capabilities to identify and classify named entities. The notebook takes plain text as input and outputs markdown where entities are annotated in the format [Entity](TYPE), such as [London](LOCATION). This approach showcases how LLMs can be used for structured information extraction tasks in cultural heritage metadata enrichment.\n",
    "\n",
    "\n",
    "### Process Overview\n",
    "\n",
    "The process consists of the following steps:\n",
    "\n",
    "1. **Import required software libraries**: We start with importing required software libraries\n",
    "2. **Read the text that requires processing**: Next we obtain the input text from the preprocessing notebook\n",
    "3. **Named entity recognition**: The text is sent to GPT with a prompt that instructs it to identify entities. The LLM marks entities in markdown format: \\[entity text\\]\\(entity type\\)\n",
    "4. **Named entity visualization**: The annotated text is displayed with colour-coded entity highlighting\n",
    "5. **Save results**: Save the results of named entity recognition for future processing\n",
    "\n",
    "This approach leverages the LLM's natural language understanding while producing structured, machine-readable output.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This notebook depends on two files:\n",
    "\n",
    "* utils.py: helper functions\n",
    "* ner_cache.json\n",
    "\n",
    "Please make sure they are available in this folder so that the notebook can run smoothly. You can download them from [Github](https://github.com/pelagios/llm-lod-enriching-heritage/tree/main/notebooks/tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ccb96",
   "metadata": {},
   "source": [
    "## 1. Import required software libraries\n",
    "\n",
    "Preprocessing data requires importing some standard software libraries. This step may take some time when run for the first time but in successive runs it will be a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3472abb-a6ca-446a-8424-8b7af78cdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c95e6-d75d-4394-904c-6d3819d07f67",
   "metadata": {},
   "source": [
    "First we import standard libraries which should always be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f5ff2d-7192-4487-9ed1-c02abcbccf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import importlib\n",
    "from IPython.display import clear_output, HTML \n",
    "import json\n",
    "import os\n",
    "import regex\n",
    "import subprocess\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771227af-0f34-4359-861a-c80ae07f38fc",
   "metadata": {},
   "source": [
    "Next we import packages which may require installation on this device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cef27a-cca0-45b9-a20d-893b3bf0ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = utils.safe_import(\"openai\")\n",
    "spacy = utils.safe_import(\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5600a-810a-4843-b213-f5cbc00603cd",
   "metadata": {},
   "source": [
    "Finally we set settings required for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0f1136-7f0c-47a4-8aaf-ce819ebcf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_colab = utils.check_google_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422d93f-eb91-422e-a6c3-c6c56a16d6d0",
   "metadata": {},
   "source": [
    "## 2. Read the text that requires processing\n",
    "\n",
    "The text should have been preprocessed by the `data_preparation.ipynb` notebook. The file read here is an output file of that notebook. We select the first text and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01e81fa-5a4a-4ed3-abfd-4008f645dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statuette of the god Anubis. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115\n"
     ]
    }
   ],
   "source": [
    "infile_name = \"output_data_preparation_11f98441067263d80ee1a6bac27babf0f2c6734b.json\"\n",
    "\n",
    "\n",
    "with open(infile_name, \"r\") as infile:\n",
    "    input_data = json.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "texts_input = [text[\"text_cleaned\"] for text in input_data]\n",
    "print(texts_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4c708",
   "metadata": {},
   "source": [
    "## 3. Named entity recognition\n",
    "\n",
    "We use OpenAI's ChatGPT for recognizing named entities in the text. For this approach you need an OpenAI API key. Store it in the environment variable OPENAI_API_KEY or in the file OPENAI_API_KEY. For alternative approaches to named entity recognition, see chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf971106-8b8f-4a45-9a91-d81bbd360e62",
   "metadata": {},
   "source": [
    "First we define two helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c2434c-50a4-4c1f-82a2-610fad9d247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(texts_input, target_labels):\n",
    "    \"\"\"Create an LLM prompt, given a text and target labels and return it\"\"\"\n",
    "    return f\"\"\"\n",
    "Convert the following text into a structured markdown format, where you annotate the entities in the text in the following format: [Tom](PERSON) went to [New York](PLACE).\n",
    "\n",
    "Look for the following entities types:\n",
    "{target_labels}\n",
    "\n",
    "Do this for the following text:\n",
    "{texts_input}\n",
    "\n",
    "Only return the markdown output, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d29d7e-8a26-411f-ba5b-05cda6d63adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "target_labels=[\"PERSON\", \"LOCATION\"]\n",
    "NER_CACHE_FILE = \"ner_cache.json\"\n",
    "\n",
    "def openai_ner(model, texts_input):\n",
    "    openai_api_key = utils.get_openai_api_key()\n",
    "    openai_client = utils.connect_to_openai(openai_api_key)\n",
    "    ner_cache = utils.read_json_file(NER_CACHE_FILE)\n",
    "    texts_output = []\n",
    "    for index, text in enumerate(texts_input):\n",
    "        if text in ner_cache and model in ner_cache[text]:\n",
    "            utils.squeal(f\"Retrieving entities for text {index + 1} from cache\")\n",
    "            texts_output.append(ner_cache[text][model])\n",
    "        else:\n",
    "            utils.squeal(f\"Processing text {index + 1} with GPT\")\n",
    "            prompt = make_prompt(text, target_labels)\n",
    "            texts_output.append(utils.process_text_with_gpt(openai_client, model, prompt))\n",
    "    utils.write_json_file(NER_CACHE_FILE, \n",
    "                          {text_input: {model: text_output} \n",
    "                           for text_input, text_output in zip(texts_input, texts_output)})\n",
    "    print(\"Finished processing\")\n",
    "    return texts_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6455ab8-f742-41f8-b126-49b756725353",
   "metadata": {},
   "source": [
    "Next, we use the functions to connect to GPT, send it the text and collect the results, which are shown in markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a66bff5e-3e90-40e9-8b9b-d595661006d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving entities for text 100 from cache\n",
      "Finished processing\n",
      "Statuette of the god [Anubis](PERSON). Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115\n"
     ]
    }
   ],
   "source": [
    "texts_output = openai_ner(model, texts_input)\n",
    "print(texts_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f086af",
   "metadata": {},
   "source": [
    "## 4. Named entity visualization\n",
    "\n",
    "Here we show the results of named entity recognition in a more readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69070e-4b5f-40af-adb2-18266231db1c",
   "metadata": {},
   "source": [
    "First we define three helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff163088-2219-42f6-9778-c72f786e698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_from_markdown(texts_output):\n",
    "    \"\"\"Extract the locations and labels of the entities from the markdown and return these\"\"\"\n",
    "    pattern = r'\\[([^\\]]+)\\]\\(([^)]+)\\)'\n",
    "    text_prefix = \"\"\n",
    "    current_char = 0\n",
    "    entities = []\n",
    "    for match in regex.finditer(pattern, texts_output):\n",
    "        text_prefix += texts_output[current_char: match.start()]\n",
    "        entities.append({\"text\": match.group(1),\n",
    "                         \"label\": match.group(2),\n",
    "                         \"start_char\": len(text_prefix), \n",
    "                         \"end_char\": len(text_prefix) + len(match.group(1))})\n",
    "        text_prefix += match.group(1)\n",
    "        current_char = match.end()\n",
    "    text_prefix += texts_output[current_char:]\n",
    "    return entities, text_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccdb03eb-b38d-4ee5-af7b-9676de01a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_llm_output_text(text_llm_output, texts_input):\n",
    "    if text_llm_output != texts_input:\n",
    "        print(f\"{utils.CHAR_FAILURE} Output text of named entity recognition is different from input text!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639606-06d2-442e-b2ec-8fb31d71d921",
   "metadata": {},
   "source": [
    "Next we call the function to extract the entities from the results, check the output text and visualize the results, for the first five results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7f5a6e-247d-4c2c-aeff-22023cee039f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Statuette of the god <span style=\"border: 1px solid black; color: red;\">Anubis</span>. Bronze. Late Period (722-332 BC).. Acquired before 1882. C. 115"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Output text of named entity recognition is different from input text!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"border: 1px solid black; color: red;\">Sekhmet</span> was a goddess. <span style=\"border: 1px solid black; color: green;\">Thebes</span> is referenced. The object is made of granodiorite and belongs to the Drovetti collection (1824). It dates back to the New Kingdom, 18th Dynasty, during the reign of <span style=\"border: 1px solid black; color: red;\">Amenhotep III</span> (1390-1353 BC)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Statuette of the goddess <span style=\"border: 1px solid black; color: red;\">Bastet</span>. Bronze. Late Period (722-332 BC).. <span style=\"border: 1px solid black; color: red;\">Drovetti</span> collection (1824). C. 271"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Output text of named entity recognition is different from input text!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"border: 1px solid black; color: red;\">Harpocrates</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Output text of named entity recognition is different from input text!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Statuette of the goddess <span style=\"border: 1px solid black; color: red;\">Satet</span>. Bronze. Late Period (722-332 BC). Drovetti collection (1824). C. 515"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entities_all = []\n",
    "for index, text in enumerate(texts_output):\n",
    "    entities, text_llm_output = extract_entities_from_markdown(text)\n",
    "    entities_all.append({\"entities\": entities, \"text_llm_output\": text_llm_output})\n",
    "    if index < 5:\n",
    "        check_llm_output_text(text_llm_output, texts_input[index])\n",
    "        display(HTML(utils.mark_entities_in_text(text_llm_output, entities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35713f16-99bd-4392-a894-dd59b594bded",
   "metadata": {},
   "source": [
    "## 5. Save results\n",
    "\n",
    "Just like in the data preprocessing notebook, we save the results in a json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56d739-d55f-4260-8aed-113311a83822",
   "metadata": {},
   "source": [
    "We define a function for saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2f355-ceb0-423e-99ea-17489f289189",
   "metadata": {},
   "source": [
    "We add the named entity analysis to the input data and save the results in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf595c60-2d89-4baf-83a7-e5a00c2e25f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "️✅ Saved preprocessed texts to file output_ner_5f12fa7c16d33ea378148197569f999f774f7481.json\n"
     ]
    }
   ],
   "source": [
    "for index, entities in enumerate(entities_all):\n",
    "    input_data[index][\"entities\"] = entities[\"entities\"]\n",
    "    input_data[index][\"text_llm_output\"] = entities[\"text_llm_output\"]\n",
    "utils.save_results(input_data, key=\"ner_\", in_colab=in_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e3666-72c9-4c18-b237-9c0d60eccbfd",
   "metadata": {},
   "source": [
    "## 6. Alternatives for named entity recognition\n",
    "\n",
    "Here we define some alternatives for recognising named entities, for example if you do not have an OpenAI API key or if you do not want to share your data with OpenAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf5dd7-a009-4426-a068-71891e052578",
   "metadata": {},
   "source": [
    "### 6.1. Spacy\n",
    "\n",
    "This named entity recognizer runs at your own computer and does not require an access key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b3214-41c9-4218-abf5-a67f6257cb6f",
   "metadata": {},
   "source": [
    "First, we define three helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7a16d8-ce60-44b8-bcd7-c36bcadb508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_MODELS = {\n",
    "    \"en\": \"en_core_web_sm\",\n",
    "    \"de\": \"de_core_news_sm\",\n",
    "    \"fr\": \"fr_core_news_sm\",\n",
    "    \"es\": \"es_core_news_sm\",\n",
    "    \"pt\": \"pt_core_news_sm\",\n",
    "    \"it\": \"it_core_news_sm\",\n",
    "    \"nl\": \"nl_core_news_sm\",\n",
    "    \"xx\": \"xx_ent_wiki_sm\"\n",
    "}\n",
    "\n",
    "def load_spacy_model(language_id):\n",
    "    \"\"\"Load the Spacy model for the current language and return it\"\"\"\n",
    "    if language_id not in LANG_MODELS.keys():\n",
    "        print(f\"{utils.CHAR_FAILURE} warning: unknown language {language_id}. Switching to multilingual model...\")\n",
    "        language_id = \"xx\"\n",
    "    try:\n",
    "        nlp = spacy.load(LANG_MODELS[language_id])\n",
    "    except:\n",
    "        try:\n",
    "            print(f\"Model {LANG_MODELS[language_id]} not found, trying to download it...\")\n",
    "            spacy.cli.download(LANG_MODELS[language_id])\n",
    "            nlp = spacy.load(LANG_MODELS[language_id])\n",
    "        except:\n",
    "            raise(RuntimeError(f\"{utils.CHAR_FAILURE} Cannot find language model {LANG_MODELS[language_id]}!\"))\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f77287b-d00c-4780-ac6d-1586241e7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_spacy_entities_to_markdown(doc, texts_input):\n",
    "    \"\"\"Extract the entities recognised by Spacy and return them in a markdown string\"\"\"\n",
    "    entities = [{\"text\": entity.text,\n",
    "                 \"label\": entity.label_,\n",
    "                 \"start_char\": entity.start_char,\n",
    "                 \"end_char\": entity.end_char} for entity in doc.ents]\n",
    "    for entity in reversed(entities):\n",
    "        if entity[\"label\"] in [\"FAC\", \"GPE\", \"LOC\"]:\n",
    "            entity[\"label\"] = \"LOCATION\"\n",
    "        if entity[\"label\"] in [\"LOCATION\", \"PERSON\"]:\n",
    "            texts_input = (texts_input[:entity[\"end_char\"]] + \n",
    "                          f\"]({entity['label']})\" + \n",
    "                          texts_input[entity[\"end_char\"]:])\n",
    "            texts_input = texts_input[:entity[\"start_char\"]] + \"[\" + texts_input[entity[\"start_char\"]:]\n",
    "    return texts_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306bd0a-84bd-4b4e-b393-e96409856899",
   "metadata": {},
   "source": [
    "Next, we call the helper functions for finding the language of the input text, selecting the right Spacy model, calling the model and converting the results to a markdown string, which is shown. The markdown string can be fed to the visualisation code of chapter 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3406011a-9d11-4dbf-bdb7-a0809530acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 100\n",
      "Finished processing\n",
      "Statuette of the god Anubis. [Bronze](PERSON). Late Period (722-332 BC).. Acquired before 1882. C. 115\n"
     ]
    }
   ],
   "source": [
    "texts_output = []\n",
    "last_language_id = \"\"\n",
    "for index, text in enumerate(texts_input):\n",
    "    utils.squeal(f\"Processing text {index + 1}\")\n",
    "    language_id = utils.detect_text_language(text)\n",
    "    if language_id != last_language_id:\n",
    "        nlp = load_spacy_model(language_id)\n",
    "        last_language_id = language_id\n",
    "    doc = nlp(text)\n",
    "    texts_output.append(convert_spacy_entities_to_markdown(doc, text))\n",
    "print(\"Finished processing\")\n",
    "print(texts_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392692b-8473-4ff0-ac1a-ed411efa9ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
